{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.feature\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ravdess_data(data_dir):\n",
    "    emotions = {\n",
    "        '01': 'neutral',\n",
    "        '02': 'calm',\n",
    "        '03': 'happy',\n",
    "        '04': 'sad',\n",
    "        '05': 'angry',\n",
    "        '06': 'fearful',\n",
    "        '07': 'disgust',\n",
    "        '08': 'surprised'\n",
    "    }\n",
    "    actors = {'01', '02', '03', '04', '05', '06', '07', '08'}\n",
    "    x = []\n",
    "    y = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "              # Load the audio file\n",
    "              filepath = os.path.join(data_dir, filename)\n",
    "              waveform, sample_rate = librosa.load(filepath, sr=None)\n",
    "\n",
    "              # Extract features\n",
    "              mfcc = librosa.feature.mfcc(y=waveform,sr=sample_rate, n_mfcc=13)\n",
    "              spectral_contrast = librosa.feature.spectral_contrast(y=waveform,sr=sample_rate)\n",
    "              features = np.concatenate((mfcc.mean(axis=1), spectral_contrast.mean(axis=1)))\n",
    "\n",
    "              # Get the emotion label from the filename\n",
    "              emotion = emotions[filename[6:8]]\n",
    "\n",
    "              x.append(features)\n",
    "              y.append(emotion)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor1_feature, actor1_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_01')\n",
    "actor2_feature, actor2_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_02')\n",
    "actor4_feature, actor4_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_04')\n",
    "actor5_feature, actor5_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_05')\n",
    "actor6_feature, actor6_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor7_feature, actor7_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_07')\n",
    "actor8_feature, actor8_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_08')\n",
    "actor9_feature, actor9_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_09')\n",
    "actor10_feature, actor10_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_10')\n",
    "actor11_feature, actor11_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_11')\n",
    "actor12_feature, actor12_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor13_feature, actor13_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_13')\n",
    "actor14_feature, actor14_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_14')\n",
    "actor15_feature, actor15_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_15')\n",
    "actor16_feature, actor16_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_16')\n",
    "actor17_feature, actor17_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_17')\n",
    "actor18_feature, actor18_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor19_feature, actor19_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_19')\n",
    "actor20_feature, actor20_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_20')\n",
    "actor21_feature, actor21_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_21')\n",
    "actor22_feature, actor22_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_22')\n",
    "actor23_feature, actor23_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_23')\n",
    "actor24_feature, actor24_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor25_feature, actor25_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_25')\n",
    "actor26_feature, actor26_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_26')\n",
    "actor27_feature, actor27_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_27')\n",
    "actor28_feature, actor28_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_28')\n",
    "actor29_feature, actor29_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor30_feature, actor30_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_30')\n",
    "actor31_feature, actor31_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_31')\n",
    "actor32_feature, actor32_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_32')\n",
    "actor33_feature, actor33_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_33')\n",
    "actor34_feature, actor34_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor35_feature, actor35_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_35')\n",
    "actor36_feature, actor36_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_36')\n",
    "actor37_feature, actor37_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_37')\n",
    "actor38_feature, actor38_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_38')\n",
    "actor39_feature, actor39_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_39')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor40_feature, actor40_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_40')\n",
    "actor41_feature, actor41_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_41')\n",
    "actor42_feature, actor42_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_42')\n",
    "actor43_feature, actor43_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_43')\n",
    "actor44_feature, actor44_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_44')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for each actor\n",
    "actor45_feature, actor45_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_45')\n",
    "actor46_feature, actor46_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_46')\n",
    "actor47_feature, actor47_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_47')\n",
    "actor48_feature, actor48_emo = load_ravdess_data('audio_speech_actors_01-24/Actor_48')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the data into a single dataset\n",
    "combined_features = np.concatenate((actor1_feature, actor2_feature,actor4_feature,actor5_feature, actor6_feature,actor7_feature,actor8_feature,actor9_feature,actor10_feature,actor11_feature,actor12_feature,actor13_feature,actor14_feature,actor15_feature,actor16_feature, actor17_feature,actor18_feature,actor19_feature,actor20_feature,actor21_feature,actor22_feature,actor23_feature, actor24_feature,actor25_feature,actor26_feature,actor27_feature,actor28_feature,actor29_feature,actor30_feature,actor31_feature,actor32_feature,actor33_feature,actor34_feature,actor35_feature,actor36_feature,actor37_feature,actor38_feature,actor39_feature,actor40_feature,actor41_feature,actor42_feature,actor43_feature,actor44_feature,actor45_feature,actor46_feature,actor47_feature,actor48_feature), axis=0)\n",
    "combined_emo=np.concatenate((actor1_emo, actor2_emo,actor4_emo,actor5_emo, actor6_emo,actor7_emo,actor8_emo,actor9_emo,actor10_emo,actor11_emo,actor12_emo,actor13_emo,actor14_emo,actor15_emo, actor16_emo,actor17_emo, actor18_emo, actor19_emo,actor20_emo,actor21_emo,actor22_emo,actor23_emo,actor24_emo,actor25_emo,actor26_emo,actor27_emo,actor28_emo,actor29_emo,actor30_emo,actor31_emo,actor32_emo,actor33_emo,actor34_emo,actor35_emo,actor36_emo,actor37_emo,actor38_emo,actor39_emo,actor40_emo,actor41_emo,actor42_emo,actor43_emo,actor44_emo,actor45_emo,actor46_emo,actor47_emo,actor48_emo), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3057, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#label encoding\n",
    "from keras.utils import to_categorical\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels_encoded = to_categorical(le.fit_transform(combined_emo))\n",
    "print(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM,Dropout\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate,Reshape\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "newmodel=Sequential()\n",
    "\n",
    "newmodel.add(Reshape(target_shape=(20, 1)))\n",
    "\n",
    "newmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(MaxPooling1D(pool_size=2))\n",
    "newmodel.add(Dropout(0.3))\n",
    "\n",
    "newmodel.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(MaxPooling1D(pool_size=2))\n",
    "newmodel.add(Dropout(0.3))\n",
    "\n",
    "newmodel.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(MaxPooling1D(pool_size=2))\n",
    "newmodel.add(Dropout(0.3))\n",
    "\n",
    "newmodel.add(Flatten())\n",
    "\n",
    "newmodel.add(Dense(1024, activation='relu'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Dropout(0.5))\n",
    "\n",
    "newmodel.add(Dense(512, activation='relu'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Dropout(0.5))\n",
    "\n",
    "newmodel.add(Dense(256, activation='relu'))\n",
    "newmodel.add(BatchNormalization())\n",
    "newmodel.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "newmodel.add(Dense(8, activation='softmax'))\n",
    "\n",
    "newmodel.compile(loss=tf.losses.CategoricalCrossentropy(), optimizer=tf.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_5 (Reshape)         (None, 20, 1)             0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 20, 64)            256       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 20, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 20, 64)            12352     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 20, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 10, 64)            0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 10, 128)           24704     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 10, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 10, 128)           49280     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 10, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 5, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 5, 128)            0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 5, 256)            98560     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 5, 256)           1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 5, 256)            196864    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 5, 256)           1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 2, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 2, 256)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,576,264\n",
      "Trainable params: 1,570,888\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "63/63 [==============================] - 7s 45ms/step - loss: 0.2362 - accuracy: 0.9335 - val_loss: 1.6457 - val_accuracy: 0.6426\n",
      "Epoch 2/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.1683 - accuracy: 0.9537 - val_loss: 1.6337 - val_accuracy: 0.6265\n",
      "Epoch 3/500\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.1306 - accuracy: 0.9627 - val_loss: 1.6823 - val_accuracy: 0.6386\n",
      "Epoch 4/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.1817 - accuracy: 0.9496 - val_loss: 1.7496 - val_accuracy: 0.6145\n",
      "Epoch 5/500\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 0.1588 - accuracy: 0.9547 - val_loss: 1.7645 - val_accuracy: 0.5984\n",
      "Epoch 6/500\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 0.1444 - accuracy: 0.9607 - val_loss: 1.6460 - val_accuracy: 0.6466\n",
      "Epoch 7/500\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.1373 - accuracy: 0.9627 - val_loss: 1.7582 - val_accuracy: 0.6265\n",
      "Epoch 8/500\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.0994 - accuracy: 0.9728 - val_loss: 1.8910 - val_accuracy: 0.6345\n",
      "Epoch 9/500\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.1196 - accuracy: 0.9668 - val_loss: 1.8621 - val_accuracy: 0.6225\n",
      "Epoch 10/500\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 1.9770 - val_accuracy: 0.5944\n",
      "Epoch 11/500\n",
      "63/63 [==============================] - 4s 65ms/step - loss: 0.0967 - accuracy: 0.9708 - val_loss: 1.9773 - val_accuracy: 0.6225\n",
      "Epoch 12/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.1022 - accuracy: 0.9748 - val_loss: 1.9682 - val_accuracy: 0.6145\n",
      "Epoch 13/500\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1195 - accuracy: 0.9627 - val_loss: 2.1202 - val_accuracy: 0.6185\n",
      "Epoch 14/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.1105 - accuracy: 0.9718 - val_loss: 2.0574 - val_accuracy: 0.6265\n",
      "Epoch 15/500\n",
      "63/63 [==============================] - 4s 67ms/step - loss: 0.1054 - accuracy: 0.9718 - val_loss: 2.0779 - val_accuracy: 0.6345\n",
      "Epoch 16/500\n",
      "63/63 [==============================] - 4s 66ms/step - loss: 0.1397 - accuracy: 0.9607 - val_loss: 2.0816 - val_accuracy: 0.6064\n",
      "Epoch 17/500\n",
      "63/63 [==============================] - 4s 69ms/step - loss: 0.1149 - accuracy: 0.9617 - val_loss: 2.0503 - val_accuracy: 0.6386\n",
      "Epoch 18/500\n",
      "63/63 [==============================] - 4s 67ms/step - loss: 0.0948 - accuracy: 0.9748 - val_loss: 2.0378 - val_accuracy: 0.6305\n",
      "Epoch 19/500\n",
      "63/63 [==============================] - 4s 67ms/step - loss: 0.0987 - accuracy: 0.9778 - val_loss: 2.2200 - val_accuracy: 0.6305\n",
      "Epoch 20/500\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1221 - accuracy: 0.9648 - val_loss: 2.1441 - val_accuracy: 0.6305\n",
      "Epoch 21/500\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 0.1387 - accuracy: 0.9637 - val_loss: 2.1662 - val_accuracy: 0.6225\n",
      "Epoch 22/500\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.1119 - accuracy: 0.9617 - val_loss: 2.1653 - val_accuracy: 0.6024\n",
      "Epoch 23/500\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1174 - accuracy: 0.9637 - val_loss: 2.1876 - val_accuracy: 0.6104\n",
      "Epoch 24/500\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.1307 - accuracy: 0.9577 - val_loss: 2.0187 - val_accuracy: 0.6426\n",
      "Epoch 25/500\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.1297 - accuracy: 0.9617 - val_loss: 2.1257 - val_accuracy: 0.6185\n",
      "Epoch 26/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.1297 - accuracy: 0.9637 - val_loss: 2.0980 - val_accuracy: 0.6506\n",
      "Epoch 27/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.1767 - accuracy: 0.9507 - val_loss: 2.1474 - val_accuracy: 0.6225\n",
      "Epoch 28/500\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.1203 - accuracy: 0.9557 - val_loss: 2.2621 - val_accuracy: 0.6104\n",
      "Epoch 29/500\n",
      "63/63 [==============================] - 3s 56ms/step - loss: 0.1426 - accuracy: 0.9617 - val_loss: 2.2450 - val_accuracy: 0.5743\n",
      "Epoch 30/500\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.1191 - accuracy: 0.9718 - val_loss: 1.8910 - val_accuracy: 0.6426\n",
      "Epoch 31/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.1197 - accuracy: 0.9627 - val_loss: 1.9643 - val_accuracy: 0.6466\n",
      "Epoch 32/500\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.0906 - accuracy: 0.9748 - val_loss: 1.9487 - val_accuracy: 0.5984\n",
      "Epoch 33/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.1119 - accuracy: 0.9668 - val_loss: 2.0114 - val_accuracy: 0.5783\n",
      "Epoch 34/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0853 - accuracy: 0.9768 - val_loss: 2.0442 - val_accuracy: 0.6145\n",
      "Epoch 35/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1144 - accuracy: 0.9668 - val_loss: 2.1453 - val_accuracy: 0.6145\n",
      "Epoch 36/500\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.0972 - accuracy: 0.9688 - val_loss: 2.0794 - val_accuracy: 0.6265\n",
      "Epoch 37/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1310 - accuracy: 0.9648 - val_loss: 2.0776 - val_accuracy: 0.6145\n",
      "Epoch 38/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.1282 - accuracy: 0.9637 - val_loss: 2.1525 - val_accuracy: 0.6024\n",
      "Epoch 39/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.1580 - accuracy: 0.9587 - val_loss: 2.1911 - val_accuracy: 0.5863\n",
      "Epoch 40/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1227 - accuracy: 0.9658 - val_loss: 2.0314 - val_accuracy: 0.6024\n",
      "Epoch 41/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0946 - accuracy: 0.9698 - val_loss: 2.0102 - val_accuracy: 0.6185\n",
      "Epoch 42/500\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.1404 - accuracy: 0.9577 - val_loss: 1.8727 - val_accuracy: 0.6305\n",
      "Epoch 43/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1251 - accuracy: 0.9587 - val_loss: 1.9349 - val_accuracy: 0.6024\n",
      "Epoch 44/500\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.1393 - accuracy: 0.9577 - val_loss: 1.8191 - val_accuracy: 0.6305\n",
      "Epoch 45/500\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.1312 - accuracy: 0.9648 - val_loss: 1.8818 - val_accuracy: 0.6265\n",
      "Epoch 46/500\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.1347 - accuracy: 0.9537 - val_loss: 1.8582 - val_accuracy: 0.6466\n",
      "Epoch 47/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1417 - accuracy: 0.9627 - val_loss: 1.8440 - val_accuracy: 0.6024\n",
      "Epoch 48/500\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.1336 - accuracy: 0.9587 - val_loss: 1.9879 - val_accuracy: 0.5984\n",
      "Epoch 49/500\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.1125 - accuracy: 0.9728 - val_loss: 1.9802 - val_accuracy: 0.6305\n",
      "Epoch 50/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0998 - accuracy: 0.9658 - val_loss: 1.9734 - val_accuracy: 0.6225\n",
      "Epoch 51/500\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1130 - accuracy: 0.9678 - val_loss: 1.9525 - val_accuracy: 0.6466\n",
      "Epoch 52/500\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.1282 - accuracy: 0.9688 - val_loss: 1.9176 - val_accuracy: 0.6586\n",
      "Epoch 53/500\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.1147 - accuracy: 0.9648 - val_loss: 1.9153 - val_accuracy: 0.6265\n",
      "Epoch 54/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.1105 - accuracy: 0.9698 - val_loss: 2.1026 - val_accuracy: 0.5984\n",
      "Epoch 55/500\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.1065 - accuracy: 0.9718 - val_loss: 2.1380 - val_accuracy: 0.6185\n",
      "Epoch 56/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.1113 - accuracy: 0.9658 - val_loss: 2.0840 - val_accuracy: 0.5984\n",
      "Epoch 57/500\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 0.1179 - accuracy: 0.9768 - val_loss: 2.1238 - val_accuracy: 0.6265\n",
      "Epoch 58/500\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1357 - accuracy: 0.9567 - val_loss: 2.2132 - val_accuracy: 0.6064\n",
      "Epoch 59/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.1089 - accuracy: 0.9627 - val_loss: 2.1783 - val_accuracy: 0.6305\n",
      "Epoch 60/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1260 - accuracy: 0.9658 - val_loss: 2.0388 - val_accuracy: 0.6305\n",
      "Epoch 61/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1295 - accuracy: 0.9627 - val_loss: 1.9985 - val_accuracy: 0.6466\n",
      "Epoch 62/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1289 - accuracy: 0.9658 - val_loss: 2.0210 - val_accuracy: 0.6305\n",
      "Epoch 63/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1428 - accuracy: 0.9587 - val_loss: 2.2666 - val_accuracy: 0.6064\n",
      "Epoch 64/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1137 - accuracy: 0.9678 - val_loss: 2.1324 - val_accuracy: 0.6145\n",
      "Epoch 65/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1205 - accuracy: 0.9658 - val_loss: 2.0044 - val_accuracy: 0.6265\n",
      "Epoch 66/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0781 - accuracy: 0.9758 - val_loss: 2.1495 - val_accuracy: 0.6024\n",
      "Epoch 67/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1206 - accuracy: 0.9627 - val_loss: 2.0262 - val_accuracy: 0.6466\n",
      "Epoch 68/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1170 - accuracy: 0.9658 - val_loss: 2.3822 - val_accuracy: 0.5944\n",
      "Epoch 69/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0842 - accuracy: 0.9789 - val_loss: 2.2214 - val_accuracy: 0.5863\n",
      "Epoch 70/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1280 - accuracy: 0.9627 - val_loss: 2.1667 - val_accuracy: 0.6265\n",
      "Epoch 71/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1309 - accuracy: 0.9567 - val_loss: 2.2397 - val_accuracy: 0.5944\n",
      "Epoch 72/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1215 - accuracy: 0.9597 - val_loss: 2.1708 - val_accuracy: 0.5944\n",
      "Epoch 73/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1316 - accuracy: 0.9648 - val_loss: 2.2028 - val_accuracy: 0.6064\n",
      "Epoch 74/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0960 - accuracy: 0.9728 - val_loss: 2.3270 - val_accuracy: 0.5904\n",
      "Epoch 75/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1521 - accuracy: 0.9637 - val_loss: 1.9271 - val_accuracy: 0.6506\n",
      "Epoch 76/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1152 - accuracy: 0.9648 - val_loss: 2.1128 - val_accuracy: 0.6185\n",
      "Epoch 77/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0755 - accuracy: 0.9738 - val_loss: 2.0580 - val_accuracy: 0.6064\n",
      "Epoch 78/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1113 - accuracy: 0.9688 - val_loss: 2.1221 - val_accuracy: 0.6386\n",
      "Epoch 79/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 2.0657 - val_accuracy: 0.6426\n",
      "Epoch 80/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1341 - accuracy: 0.9627 - val_loss: 2.0956 - val_accuracy: 0.6104\n",
      "Epoch 81/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1297 - accuracy: 0.9678 - val_loss: 2.1274 - val_accuracy: 0.6145\n",
      "Epoch 82/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1333 - accuracy: 0.9607 - val_loss: 2.1563 - val_accuracy: 0.6024\n",
      "Epoch 83/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1322 - accuracy: 0.9627 - val_loss: 2.2279 - val_accuracy: 0.5863\n",
      "Epoch 84/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1136 - accuracy: 0.9658 - val_loss: 2.3002 - val_accuracy: 0.5984\n",
      "Epoch 85/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1377 - accuracy: 0.9658 - val_loss: 2.0774 - val_accuracy: 0.6265\n",
      "Epoch 86/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1215 - accuracy: 0.9668 - val_loss: 2.0712 - val_accuracy: 0.6145\n",
      "Epoch 87/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.1451 - accuracy: 0.9648 - val_loss: 2.1161 - val_accuracy: 0.6024\n",
      "Epoch 88/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1287 - accuracy: 0.9637 - val_loss: 2.0436 - val_accuracy: 0.6024\n",
      "Epoch 89/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0916 - accuracy: 0.9728 - val_loss: 2.1086 - val_accuracy: 0.6104\n",
      "Epoch 90/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1346 - accuracy: 0.9627 - val_loss: 2.1741 - val_accuracy: 0.5984\n",
      "Epoch 91/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1449 - accuracy: 0.9567 - val_loss: 2.0475 - val_accuracy: 0.5944\n",
      "Epoch 92/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1469 - accuracy: 0.9617 - val_loss: 1.9579 - val_accuracy: 0.6145\n",
      "Epoch 93/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0986 - accuracy: 0.9718 - val_loss: 2.0476 - val_accuracy: 0.6104\n",
      "Epoch 94/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1332 - accuracy: 0.9658 - val_loss: 2.0725 - val_accuracy: 0.6185\n",
      "Epoch 95/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1052 - accuracy: 0.9728 - val_loss: 2.0158 - val_accuracy: 0.6305\n",
      "Epoch 96/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1317 - accuracy: 0.9597 - val_loss: 1.9437 - val_accuracy: 0.6305\n",
      "Epoch 97/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1185 - accuracy: 0.9648 - val_loss: 1.8776 - val_accuracy: 0.6145\n",
      "Epoch 98/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1067 - accuracy: 0.9728 - val_loss: 2.1738 - val_accuracy: 0.5984\n",
      "Epoch 99/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0978 - accuracy: 0.9688 - val_loss: 2.1372 - val_accuracy: 0.6185\n",
      "Epoch 100/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1003 - accuracy: 0.9718 - val_loss: 2.1435 - val_accuracy: 0.6145\n",
      "Epoch 101/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0800 - accuracy: 0.9799 - val_loss: 2.2205 - val_accuracy: 0.5823\n",
      "Epoch 102/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0816 - accuracy: 0.9728 - val_loss: 2.2134 - val_accuracy: 0.5863\n",
      "Epoch 103/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.1395 - accuracy: 0.9648 - val_loss: 2.2319 - val_accuracy: 0.6024\n",
      "Epoch 104/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0997 - accuracy: 0.9748 - val_loss: 2.0788 - val_accuracy: 0.5863\n",
      "Epoch 105/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1162 - accuracy: 0.9658 - val_loss: 2.0843 - val_accuracy: 0.6345\n",
      "Epoch 106/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1120 - accuracy: 0.9698 - val_loss: 1.9948 - val_accuracy: 0.5904\n",
      "Epoch 107/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0910 - accuracy: 0.9758 - val_loss: 2.1569 - val_accuracy: 0.5944\n",
      "Epoch 108/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1138 - accuracy: 0.9668 - val_loss: 2.1079 - val_accuracy: 0.6145\n",
      "Epoch 109/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1182 - accuracy: 0.9708 - val_loss: 2.1030 - val_accuracy: 0.6104\n",
      "Epoch 110/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1079 - accuracy: 0.9698 - val_loss: 2.1431 - val_accuracy: 0.5944\n",
      "Epoch 111/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1177 - accuracy: 0.9668 - val_loss: 2.1234 - val_accuracy: 0.6104\n",
      "Epoch 112/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1195 - accuracy: 0.9658 - val_loss: 2.1802 - val_accuracy: 0.5823\n",
      "Epoch 113/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1319 - accuracy: 0.9668 - val_loss: 1.9763 - val_accuracy: 0.6225\n",
      "Epoch 114/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1357 - accuracy: 0.9648 - val_loss: 2.1285 - val_accuracy: 0.5984\n",
      "Epoch 115/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1369 - accuracy: 0.9688 - val_loss: 2.0194 - val_accuracy: 0.6024\n",
      "Epoch 116/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0979 - accuracy: 0.9678 - val_loss: 2.0422 - val_accuracy: 0.6305\n",
      "Epoch 117/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0740 - accuracy: 0.9799 - val_loss: 1.9584 - val_accuracy: 0.6345\n",
      "Epoch 118/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0915 - accuracy: 0.9728 - val_loss: 2.2220 - val_accuracy: 0.6064\n",
      "Epoch 119/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1488 - accuracy: 0.9547 - val_loss: 1.9847 - val_accuracy: 0.6386\n",
      "Epoch 120/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0906 - accuracy: 0.9738 - val_loss: 2.1564 - val_accuracy: 0.6104\n",
      "Epoch 121/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1101 - accuracy: 0.9648 - val_loss: 1.9583 - val_accuracy: 0.6265\n",
      "Epoch 122/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1105 - accuracy: 0.9658 - val_loss: 2.0840 - val_accuracy: 0.6345\n",
      "Epoch 123/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1366 - accuracy: 0.9627 - val_loss: 2.0148 - val_accuracy: 0.6305\n",
      "Epoch 124/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0863 - accuracy: 0.9778 - val_loss: 2.0424 - val_accuracy: 0.6265\n",
      "Epoch 125/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1421 - accuracy: 0.9587 - val_loss: 1.9060 - val_accuracy: 0.6466\n",
      "Epoch 126/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1462 - accuracy: 0.9607 - val_loss: 2.0081 - val_accuracy: 0.6024\n",
      "Epoch 127/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1215 - accuracy: 0.9668 - val_loss: 1.8737 - val_accuracy: 0.6506\n",
      "Epoch 128/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0795 - accuracy: 0.9789 - val_loss: 1.9382 - val_accuracy: 0.6345\n",
      "Epoch 129/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0806 - accuracy: 0.9728 - val_loss: 1.9165 - val_accuracy: 0.6386\n",
      "Epoch 130/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1039 - accuracy: 0.9698 - val_loss: 2.1526 - val_accuracy: 0.6225\n",
      "Epoch 131/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0903 - accuracy: 0.9768 - val_loss: 2.0897 - val_accuracy: 0.6305\n",
      "Epoch 132/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0938 - accuracy: 0.9668 - val_loss: 1.9688 - val_accuracy: 0.6466\n",
      "Epoch 133/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1055 - accuracy: 0.9728 - val_loss: 2.0709 - val_accuracy: 0.6145\n",
      "Epoch 134/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0984 - accuracy: 0.9768 - val_loss: 2.1737 - val_accuracy: 0.6145\n",
      "Epoch 135/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0963 - accuracy: 0.9668 - val_loss: 2.0506 - val_accuracy: 0.6546\n",
      "Epoch 136/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0805 - accuracy: 0.9768 - val_loss: 2.2430 - val_accuracy: 0.6225\n",
      "Epoch 137/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0815 - accuracy: 0.9768 - val_loss: 2.3389 - val_accuracy: 0.6265\n",
      "Epoch 138/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1119 - accuracy: 0.9678 - val_loss: 2.1302 - val_accuracy: 0.6024\n",
      "Epoch 139/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0840 - accuracy: 0.9728 - val_loss: 2.1187 - val_accuracy: 0.6104\n",
      "Epoch 140/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1029 - accuracy: 0.9708 - val_loss: 2.1449 - val_accuracy: 0.6386\n",
      "Epoch 141/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1142 - accuracy: 0.9617 - val_loss: 2.0148 - val_accuracy: 0.6546\n",
      "Epoch 142/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1112 - accuracy: 0.9668 - val_loss: 2.0563 - val_accuracy: 0.6345\n",
      "Epoch 143/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1159 - accuracy: 0.9617 - val_loss: 2.1092 - val_accuracy: 0.6305\n",
      "Epoch 144/500\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.1353 - accuracy: 0.9627 - val_loss: 2.1001 - val_accuracy: 0.6185\n",
      "Epoch 145/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1526 - accuracy: 0.9637 - val_loss: 2.0067 - val_accuracy: 0.6586\n",
      "Epoch 146/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1342 - accuracy: 0.9648 - val_loss: 2.0607 - val_accuracy: 0.6466\n",
      "Epoch 147/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1138 - accuracy: 0.9688 - val_loss: 1.8407 - val_accuracy: 0.6426\n",
      "Epoch 148/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0820 - accuracy: 0.9728 - val_loss: 1.9678 - val_accuracy: 0.6305\n",
      "Epoch 149/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0925 - accuracy: 0.9688 - val_loss: 2.1338 - val_accuracy: 0.6265\n",
      "Epoch 150/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1007 - accuracy: 0.9698 - val_loss: 2.0883 - val_accuracy: 0.6145\n",
      "Epoch 151/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0897 - accuracy: 0.9748 - val_loss: 2.0720 - val_accuracy: 0.6265\n",
      "Epoch 152/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0737 - accuracy: 0.9799 - val_loss: 2.1177 - val_accuracy: 0.6265\n",
      "Epoch 153/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1459 - accuracy: 0.9607 - val_loss: 2.1276 - val_accuracy: 0.6145\n",
      "Epoch 154/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1168 - accuracy: 0.9698 - val_loss: 2.2112 - val_accuracy: 0.6265\n",
      "Epoch 155/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0817 - accuracy: 0.9748 - val_loss: 2.1376 - val_accuracy: 0.6426\n",
      "Epoch 156/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1628 - accuracy: 0.9547 - val_loss: 1.9160 - val_accuracy: 0.6426\n",
      "Epoch 157/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0818 - accuracy: 0.9748 - val_loss: 1.9348 - val_accuracy: 0.6386\n",
      "Epoch 158/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1105 - accuracy: 0.9678 - val_loss: 2.1029 - val_accuracy: 0.5944\n",
      "Epoch 159/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0637 - accuracy: 0.9789 - val_loss: 2.0733 - val_accuracy: 0.6024\n",
      "Epoch 160/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1118 - accuracy: 0.9688 - val_loss: 2.0015 - val_accuracy: 0.6426\n",
      "Epoch 161/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0923 - accuracy: 0.9758 - val_loss: 2.1365 - val_accuracy: 0.6426\n",
      "Epoch 162/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1017 - accuracy: 0.9728 - val_loss: 2.1931 - val_accuracy: 0.6145\n",
      "Epoch 163/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0739 - accuracy: 0.9799 - val_loss: 2.0570 - val_accuracy: 0.6305\n",
      "Epoch 164/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0796 - accuracy: 0.9748 - val_loss: 1.9875 - val_accuracy: 0.6386\n",
      "Epoch 165/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0984 - accuracy: 0.9768 - val_loss: 2.0361 - val_accuracy: 0.6225\n",
      "Epoch 166/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0876 - accuracy: 0.9778 - val_loss: 2.0814 - val_accuracy: 0.6225\n",
      "Epoch 167/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1192 - accuracy: 0.9688 - val_loss: 2.0534 - val_accuracy: 0.6386\n",
      "Epoch 168/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1137 - accuracy: 0.9708 - val_loss: 1.9687 - val_accuracy: 0.6305\n",
      "Epoch 169/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0913 - accuracy: 0.9648 - val_loss: 1.9523 - val_accuracy: 0.6265\n",
      "Epoch 170/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0912 - accuracy: 0.9708 - val_loss: 2.0642 - val_accuracy: 0.6546\n",
      "Epoch 171/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1068 - accuracy: 0.9688 - val_loss: 1.9693 - val_accuracy: 0.6506\n",
      "Epoch 172/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0762 - accuracy: 0.9768 - val_loss: 2.0789 - val_accuracy: 0.6305\n",
      "Epoch 173/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0953 - accuracy: 0.9758 - val_loss: 2.1027 - val_accuracy: 0.6345\n",
      "Epoch 174/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0921 - accuracy: 0.9718 - val_loss: 2.0095 - val_accuracy: 0.6546\n",
      "Epoch 175/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1063 - accuracy: 0.9748 - val_loss: 2.1848 - val_accuracy: 0.6265\n",
      "Epoch 176/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0893 - accuracy: 0.9778 - val_loss: 2.1395 - val_accuracy: 0.6265\n",
      "Epoch 177/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1337 - accuracy: 0.9678 - val_loss: 1.9571 - val_accuracy: 0.6586\n",
      "Epoch 178/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0777 - accuracy: 0.9819 - val_loss: 2.1134 - val_accuracy: 0.6345\n",
      "Epoch 179/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0938 - accuracy: 0.9688 - val_loss: 2.1221 - val_accuracy: 0.6426\n",
      "Epoch 180/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1086 - accuracy: 0.9748 - val_loss: 2.1211 - val_accuracy: 0.6145\n",
      "Epoch 181/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0572 - accuracy: 0.9879 - val_loss: 1.8605 - val_accuracy: 0.6707\n",
      "Epoch 182/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0686 - accuracy: 0.9789 - val_loss: 2.2309 - val_accuracy: 0.6345\n",
      "Epoch 183/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0913 - accuracy: 0.9768 - val_loss: 1.9792 - val_accuracy: 0.6386\n",
      "Epoch 184/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0701 - accuracy: 0.9819 - val_loss: 2.1727 - val_accuracy: 0.6104\n",
      "Epoch 185/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1064 - accuracy: 0.9698 - val_loss: 2.0790 - val_accuracy: 0.6386\n",
      "Epoch 186/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0838 - accuracy: 0.9819 - val_loss: 1.9808 - val_accuracy: 0.6305\n",
      "Epoch 187/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1044 - accuracy: 0.9738 - val_loss: 1.9514 - val_accuracy: 0.6345\n",
      "Epoch 188/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1250 - accuracy: 0.9678 - val_loss: 2.1480 - val_accuracy: 0.6265\n",
      "Epoch 189/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0604 - accuracy: 0.9778 - val_loss: 2.0165 - val_accuracy: 0.6466\n",
      "Epoch 190/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0799 - accuracy: 0.9748 - val_loss: 2.1252 - val_accuracy: 0.6305\n",
      "Epoch 191/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1756 - accuracy: 0.9527 - val_loss: 1.9205 - val_accuracy: 0.6466\n",
      "Epoch 192/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1786 - accuracy: 0.9577 - val_loss: 1.8275 - val_accuracy: 0.6466\n",
      "Epoch 193/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1190 - accuracy: 0.9658 - val_loss: 1.9412 - val_accuracy: 0.6345\n",
      "Epoch 194/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1133 - accuracy: 0.9728 - val_loss: 1.9929 - val_accuracy: 0.6104\n",
      "Epoch 195/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1032 - accuracy: 0.9648 - val_loss: 1.9222 - val_accuracy: 0.6145\n",
      "Epoch 196/500\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.0902 - accuracy: 0.9698 - val_loss: 1.9879 - val_accuracy: 0.6185\n",
      "Epoch 197/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0972 - accuracy: 0.9688 - val_loss: 2.0055 - val_accuracy: 0.6225\n",
      "Epoch 198/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0642 - accuracy: 0.9839 - val_loss: 2.0993 - val_accuracy: 0.6305\n",
      "Epoch 199/500\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0869 - accuracy: 0.9748 - val_loss: 2.1710 - val_accuracy: 0.6225\n",
      "Epoch 200/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1145 - accuracy: 0.9688 - val_loss: 2.3597 - val_accuracy: 0.6024\n",
      "Epoch 201/500\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0875 - accuracy: 0.9728 - val_loss: 2.1795 - val_accuracy: 0.6145\n",
      "Epoch 202/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1286 - accuracy: 0.9708 - val_loss: 1.9342 - val_accuracy: 0.6426\n",
      "Epoch 203/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0917 - accuracy: 0.9748 - val_loss: 2.0633 - val_accuracy: 0.6345\n",
      "Epoch 204/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1270 - accuracy: 0.9607 - val_loss: 1.9992 - val_accuracy: 0.6145\n",
      "Epoch 205/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1269 - accuracy: 0.9637 - val_loss: 2.1491 - val_accuracy: 0.6024\n",
      "Epoch 206/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0851 - accuracy: 0.9708 - val_loss: 2.0487 - val_accuracy: 0.6064\n",
      "Epoch 207/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0602 - accuracy: 0.9839 - val_loss: 1.9483 - val_accuracy: 0.6426\n",
      "Epoch 208/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0543 - accuracy: 0.9849 - val_loss: 2.0503 - val_accuracy: 0.6345\n",
      "Epoch 209/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0731 - accuracy: 0.9768 - val_loss: 1.8410 - val_accuracy: 0.6867\n",
      "Epoch 210/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0939 - accuracy: 0.9748 - val_loss: 1.9657 - val_accuracy: 0.6546\n",
      "Epoch 211/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1363 - accuracy: 0.9637 - val_loss: 2.0487 - val_accuracy: 0.5984\n",
      "Epoch 212/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1099 - accuracy: 0.9728 - val_loss: 1.9936 - val_accuracy: 0.6265\n",
      "Epoch 213/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0839 - accuracy: 0.9728 - val_loss: 1.9043 - val_accuracy: 0.6426\n",
      "Epoch 214/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0930 - accuracy: 0.9698 - val_loss: 1.9640 - val_accuracy: 0.6386\n",
      "Epoch 215/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0589 - accuracy: 0.9789 - val_loss: 1.9370 - val_accuracy: 0.6506\n",
      "Epoch 216/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0570 - accuracy: 0.9839 - val_loss: 2.0666 - val_accuracy: 0.6426\n",
      "Epoch 217/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1105 - accuracy: 0.9708 - val_loss: 2.0310 - val_accuracy: 0.6265\n",
      "Epoch 218/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0756 - accuracy: 0.9829 - val_loss: 2.0851 - val_accuracy: 0.6265\n",
      "Epoch 219/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0823 - accuracy: 0.9748 - val_loss: 2.1009 - val_accuracy: 0.6185\n",
      "Epoch 220/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1134 - accuracy: 0.9698 - val_loss: 2.2094 - val_accuracy: 0.6225\n",
      "Epoch 221/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0964 - accuracy: 0.9758 - val_loss: 2.0453 - val_accuracy: 0.6345\n",
      "Epoch 222/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1143 - accuracy: 0.9688 - val_loss: 2.0825 - val_accuracy: 0.6104\n",
      "Epoch 223/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1024 - accuracy: 0.9698 - val_loss: 2.1105 - val_accuracy: 0.6064\n",
      "Epoch 224/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0763 - accuracy: 0.9778 - val_loss: 2.1554 - val_accuracy: 0.6024\n",
      "Epoch 225/500\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0986 - accuracy: 0.9668 - val_loss: 2.1206 - val_accuracy: 0.6024\n",
      "Epoch 226/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1059 - accuracy: 0.9789 - val_loss: 2.1086 - val_accuracy: 0.6064\n",
      "Epoch 227/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1086 - accuracy: 0.9728 - val_loss: 2.0635 - val_accuracy: 0.6225\n",
      "Epoch 228/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0822 - accuracy: 0.9789 - val_loss: 2.1910 - val_accuracy: 0.5984\n",
      "Epoch 229/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0775 - accuracy: 0.9778 - val_loss: 2.1101 - val_accuracy: 0.6145\n",
      "Epoch 230/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0798 - accuracy: 0.9829 - val_loss: 2.1380 - val_accuracy: 0.6225\n",
      "Epoch 231/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0908 - accuracy: 0.9748 - val_loss: 2.2128 - val_accuracy: 0.6225\n",
      "Epoch 232/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1289 - accuracy: 0.9678 - val_loss: 2.0439 - val_accuracy: 0.6386\n",
      "Epoch 233/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0941 - accuracy: 0.9708 - val_loss: 2.1216 - val_accuracy: 0.6265\n",
      "Epoch 234/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0526 - accuracy: 0.9819 - val_loss: 2.0205 - val_accuracy: 0.6586\n",
      "Epoch 235/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0829 - accuracy: 0.9789 - val_loss: 2.1973 - val_accuracy: 0.6185\n",
      "Epoch 236/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0650 - accuracy: 0.9849 - val_loss: 2.0909 - val_accuracy: 0.6426\n",
      "Epoch 237/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0714 - accuracy: 0.9809 - val_loss: 2.1906 - val_accuracy: 0.6225\n",
      "Epoch 238/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1240 - accuracy: 0.9728 - val_loss: 2.1943 - val_accuracy: 0.6506\n",
      "Epoch 239/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1135 - accuracy: 0.9678 - val_loss: 2.2425 - val_accuracy: 0.6104\n",
      "Epoch 240/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1124 - accuracy: 0.9668 - val_loss: 2.2189 - val_accuracy: 0.6104\n",
      "Epoch 241/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1078 - accuracy: 0.9738 - val_loss: 2.1337 - val_accuracy: 0.6305\n",
      "Epoch 242/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1054 - accuracy: 0.9688 - val_loss: 2.2450 - val_accuracy: 0.6185\n",
      "Epoch 243/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1012 - accuracy: 0.9728 - val_loss: 2.1226 - val_accuracy: 0.6305\n",
      "Epoch 244/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1359 - accuracy: 0.9688 - val_loss: 2.1205 - val_accuracy: 0.6305\n",
      "Epoch 245/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0646 - accuracy: 0.9809 - val_loss: 2.1518 - val_accuracy: 0.6225\n",
      "Epoch 246/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0953 - accuracy: 0.9799 - val_loss: 2.1042 - val_accuracy: 0.6386\n",
      "Epoch 247/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1127 - accuracy: 0.9728 - val_loss: 2.0357 - val_accuracy: 0.6225\n",
      "Epoch 248/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 2.2055 - val_accuracy: 0.6145\n",
      "Epoch 249/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0914 - accuracy: 0.9758 - val_loss: 2.0520 - val_accuracy: 0.6265\n",
      "Epoch 250/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1015 - accuracy: 0.9728 - val_loss: 1.9742 - val_accuracy: 0.6546\n",
      "Epoch 251/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0798 - accuracy: 0.9778 - val_loss: 1.9007 - val_accuracy: 0.6345\n",
      "Epoch 252/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0524 - accuracy: 0.9879 - val_loss: 1.9830 - val_accuracy: 0.6225\n",
      "Epoch 253/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0636 - accuracy: 0.9829 - val_loss: 1.9973 - val_accuracy: 0.6305\n",
      "Epoch 254/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0595 - accuracy: 0.9789 - val_loss: 2.2153 - val_accuracy: 0.6104\n",
      "Epoch 255/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0928 - accuracy: 0.9768 - val_loss: 1.9267 - val_accuracy: 0.6546\n",
      "Epoch 256/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0960 - accuracy: 0.9728 - val_loss: 2.0799 - val_accuracy: 0.6426\n",
      "Epoch 257/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0757 - accuracy: 0.9799 - val_loss: 2.2638 - val_accuracy: 0.5904\n",
      "Epoch 258/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1079 - accuracy: 0.9738 - val_loss: 2.1667 - val_accuracy: 0.6225\n",
      "Epoch 259/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1134 - accuracy: 0.9789 - val_loss: 2.1881 - val_accuracy: 0.5944\n",
      "Epoch 260/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1138 - accuracy: 0.9688 - val_loss: 2.0969 - val_accuracy: 0.5984\n",
      "Epoch 261/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1050 - accuracy: 0.9758 - val_loss: 1.8613 - val_accuracy: 0.6426\n",
      "Epoch 262/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0806 - accuracy: 0.9799 - val_loss: 2.1147 - val_accuracy: 0.5904\n",
      "Epoch 263/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1069 - accuracy: 0.9768 - val_loss: 2.0987 - val_accuracy: 0.6064\n",
      "Epoch 264/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0957 - accuracy: 0.9698 - val_loss: 1.8698 - val_accuracy: 0.6104\n",
      "Epoch 265/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0770 - accuracy: 0.9809 - val_loss: 1.9490 - val_accuracy: 0.6185\n",
      "Epoch 266/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0555 - accuracy: 0.9879 - val_loss: 1.8929 - val_accuracy: 0.6305\n",
      "Epoch 267/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0927 - accuracy: 0.9778 - val_loss: 1.8734 - val_accuracy: 0.6506\n",
      "Epoch 268/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 2.1146 - val_accuracy: 0.6145\n",
      "Epoch 269/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0833 - accuracy: 0.9809 - val_loss: 2.0543 - val_accuracy: 0.6506\n",
      "Epoch 270/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0572 - accuracy: 0.9849 - val_loss: 2.1041 - val_accuracy: 0.6265\n",
      "Epoch 271/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0844 - accuracy: 0.9768 - val_loss: 2.2324 - val_accuracy: 0.6104\n",
      "Epoch 272/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0805 - accuracy: 0.9809 - val_loss: 2.1817 - val_accuracy: 0.6386\n",
      "Epoch 273/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0994 - accuracy: 0.9728 - val_loss: 2.1122 - val_accuracy: 0.6265\n",
      "Epoch 274/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1046 - accuracy: 0.9738 - val_loss: 1.9353 - val_accuracy: 0.6787\n",
      "Epoch 275/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1007 - accuracy: 0.9758 - val_loss: 2.1951 - val_accuracy: 0.6225\n",
      "Epoch 276/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.1063 - accuracy: 0.9668 - val_loss: 1.9908 - val_accuracy: 0.6185\n",
      "Epoch 277/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0934 - accuracy: 0.9748 - val_loss: 2.0520 - val_accuracy: 0.6104\n",
      "Epoch 278/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0761 - accuracy: 0.9819 - val_loss: 2.1242 - val_accuracy: 0.6064\n",
      "Epoch 279/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0856 - accuracy: 0.9778 - val_loss: 2.1792 - val_accuracy: 0.6185\n",
      "Epoch 280/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0924 - accuracy: 0.9708 - val_loss: 2.1827 - val_accuracy: 0.6104\n",
      "Epoch 281/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0880 - accuracy: 0.9768 - val_loss: 2.0063 - val_accuracy: 0.6627\n",
      "Epoch 282/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 2.0144 - val_accuracy: 0.6627\n",
      "Epoch 283/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1249 - accuracy: 0.9718 - val_loss: 2.0364 - val_accuracy: 0.6506\n",
      "Epoch 284/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0661 - accuracy: 0.9849 - val_loss: 2.0436 - val_accuracy: 0.6265\n",
      "Epoch 285/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0923 - accuracy: 0.9738 - val_loss: 1.9165 - val_accuracy: 0.6225\n",
      "Epoch 286/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1038 - accuracy: 0.9728 - val_loss: 1.9524 - val_accuracy: 0.6426\n",
      "Epoch 287/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 2.0157 - val_accuracy: 0.6225\n",
      "Epoch 288/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0880 - accuracy: 0.9708 - val_loss: 2.1793 - val_accuracy: 0.6064\n",
      "Epoch 289/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0831 - accuracy: 0.9789 - val_loss: 2.2622 - val_accuracy: 0.6265\n",
      "Epoch 290/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0913 - accuracy: 0.9728 - val_loss: 2.0327 - val_accuracy: 0.6466\n",
      "Epoch 291/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1183 - accuracy: 0.9698 - val_loss: 2.0976 - val_accuracy: 0.6466\n",
      "Epoch 292/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0753 - accuracy: 0.9819 - val_loss: 2.1076 - val_accuracy: 0.6386\n",
      "Epoch 293/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0781 - accuracy: 0.9778 - val_loss: 2.1343 - val_accuracy: 0.6185\n",
      "Epoch 294/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0882 - accuracy: 0.9728 - val_loss: 2.0960 - val_accuracy: 0.6506\n",
      "Epoch 295/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0713 - accuracy: 0.9809 - val_loss: 2.2098 - val_accuracy: 0.6104\n",
      "Epoch 296/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1038 - accuracy: 0.9758 - val_loss: 2.1245 - val_accuracy: 0.6265\n",
      "Epoch 297/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0675 - accuracy: 0.9819 - val_loss: 2.0639 - val_accuracy: 0.6466\n",
      "Epoch 298/500\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.0815 - accuracy: 0.9778 - val_loss: 2.0673 - val_accuracy: 0.6225\n",
      "Epoch 299/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0470 - accuracy: 0.9940 - val_loss: 2.0497 - val_accuracy: 0.6426\n",
      "Epoch 300/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0908 - accuracy: 0.9758 - val_loss: 2.0696 - val_accuracy: 0.6185\n",
      "Epoch 301/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0908 - accuracy: 0.9778 - val_loss: 2.1772 - val_accuracy: 0.6305\n",
      "Epoch 302/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0575 - accuracy: 0.9839 - val_loss: 2.1952 - val_accuracy: 0.6305\n",
      "Epoch 303/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0619 - accuracy: 0.9809 - val_loss: 2.2136 - val_accuracy: 0.6225\n",
      "Epoch 304/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0810 - accuracy: 0.9809 - val_loss: 2.2413 - val_accuracy: 0.6506\n",
      "Epoch 305/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1060 - accuracy: 0.9718 - val_loss: 2.3366 - val_accuracy: 0.5823\n",
      "Epoch 306/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0940 - accuracy: 0.9718 - val_loss: 2.3157 - val_accuracy: 0.6024\n",
      "Epoch 307/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1092 - accuracy: 0.9718 - val_loss: 2.2807 - val_accuracy: 0.5823\n",
      "Epoch 308/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0776 - accuracy: 0.9768 - val_loss: 2.2301 - val_accuracy: 0.6506\n",
      "Epoch 309/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0725 - accuracy: 0.9819 - val_loss: 2.1786 - val_accuracy: 0.6305\n",
      "Epoch 310/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0963 - accuracy: 0.9799 - val_loss: 2.2833 - val_accuracy: 0.6225\n",
      "Epoch 311/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0777 - accuracy: 0.9778 - val_loss: 2.1522 - val_accuracy: 0.6185\n",
      "Epoch 312/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 2.1804 - val_accuracy: 0.6225\n",
      "Epoch 313/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0795 - accuracy: 0.9718 - val_loss: 2.0471 - val_accuracy: 0.6064\n",
      "Epoch 314/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1008 - accuracy: 0.9789 - val_loss: 2.3216 - val_accuracy: 0.5622\n",
      "Epoch 315/500\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.0995 - accuracy: 0.9708 - val_loss: 2.0041 - val_accuracy: 0.6185\n",
      "Epoch 316/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0881 - accuracy: 0.9768 - val_loss: 2.1073 - val_accuracy: 0.6265\n",
      "Epoch 317/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0803 - accuracy: 0.9789 - val_loss: 2.3589 - val_accuracy: 0.5743\n",
      "Epoch 318/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0648 - accuracy: 0.9839 - val_loss: 2.2172 - val_accuracy: 0.6305\n",
      "Epoch 319/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0842 - accuracy: 0.9758 - val_loss: 2.2258 - val_accuracy: 0.6506\n",
      "Epoch 320/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0657 - accuracy: 0.9829 - val_loss: 2.0671 - val_accuracy: 0.6386\n",
      "Epoch 321/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0616 - accuracy: 0.9839 - val_loss: 2.0879 - val_accuracy: 0.6426\n",
      "Epoch 322/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0626 - accuracy: 0.9829 - val_loss: 2.0598 - val_accuracy: 0.6386\n",
      "Epoch 323/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0978 - accuracy: 0.9748 - val_loss: 2.1958 - val_accuracy: 0.6305\n",
      "Epoch 324/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0952 - accuracy: 0.9758 - val_loss: 2.0702 - val_accuracy: 0.6586\n",
      "Epoch 325/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0750 - accuracy: 0.9789 - val_loss: 2.0056 - val_accuracy: 0.6506\n",
      "Epoch 326/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0826 - accuracy: 0.9829 - val_loss: 2.0726 - val_accuracy: 0.6426\n",
      "Epoch 327/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0861 - accuracy: 0.9768 - val_loss: 2.1897 - val_accuracy: 0.5904\n",
      "Epoch 328/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0590 - accuracy: 0.9839 - val_loss: 2.2228 - val_accuracy: 0.6104\n",
      "Epoch 329/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0829 - accuracy: 0.9789 - val_loss: 2.1658 - val_accuracy: 0.6426\n",
      "Epoch 330/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0632 - accuracy: 0.9839 - val_loss: 2.2256 - val_accuracy: 0.6386\n",
      "Epoch 331/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0680 - accuracy: 0.9789 - val_loss: 2.2418 - val_accuracy: 0.6265\n",
      "Epoch 332/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0930 - accuracy: 0.9789 - val_loss: 2.2880 - val_accuracy: 0.6506\n",
      "Epoch 333/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0888 - accuracy: 0.9799 - val_loss: 2.3959 - val_accuracy: 0.6145\n",
      "Epoch 334/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0692 - accuracy: 0.9809 - val_loss: 2.3198 - val_accuracy: 0.6225\n",
      "Epoch 335/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0869 - accuracy: 0.9738 - val_loss: 2.1197 - val_accuracy: 0.6466\n",
      "Epoch 336/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0643 - accuracy: 0.9809 - val_loss: 2.2983 - val_accuracy: 0.5944\n",
      "Epoch 337/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0756 - accuracy: 0.9799 - val_loss: 2.2509 - val_accuracy: 0.6104\n",
      "Epoch 338/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1061 - accuracy: 0.9738 - val_loss: 2.3015 - val_accuracy: 0.6345\n",
      "Epoch 339/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1188 - accuracy: 0.9668 - val_loss: 2.3223 - val_accuracy: 0.6345\n",
      "Epoch 340/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 2.4127 - val_accuracy: 0.6185\n",
      "Epoch 341/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0950 - accuracy: 0.9698 - val_loss: 2.2457 - val_accuracy: 0.6345\n",
      "Epoch 342/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0873 - accuracy: 0.9768 - val_loss: 2.2775 - val_accuracy: 0.6145\n",
      "Epoch 343/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0780 - accuracy: 0.9789 - val_loss: 2.3732 - val_accuracy: 0.6104\n",
      "Epoch 344/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0940 - accuracy: 0.9738 - val_loss: 2.2325 - val_accuracy: 0.6265\n",
      "Epoch 345/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1089 - accuracy: 0.9668 - val_loss: 2.3228 - val_accuracy: 0.5863\n",
      "Epoch 346/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1192 - accuracy: 0.9668 - val_loss: 2.1973 - val_accuracy: 0.6546\n",
      "Epoch 347/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 2.1718 - val_accuracy: 0.6265\n",
      "Epoch 348/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0746 - accuracy: 0.9799 - val_loss: 2.2541 - val_accuracy: 0.6386\n",
      "Epoch 349/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1313 - accuracy: 0.9708 - val_loss: 2.2589 - val_accuracy: 0.5944\n",
      "Epoch 350/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0707 - accuracy: 0.9829 - val_loss: 2.2268 - val_accuracy: 0.6024\n",
      "Epoch 351/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 2.2178 - val_accuracy: 0.6024\n",
      "Epoch 352/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0781 - accuracy: 0.9789 - val_loss: 2.0627 - val_accuracy: 0.6546\n",
      "Epoch 353/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0655 - accuracy: 0.9778 - val_loss: 2.0793 - val_accuracy: 0.6345\n",
      "Epoch 354/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0731 - accuracy: 0.9718 - val_loss: 2.2112 - val_accuracy: 0.6064\n",
      "Epoch 355/500\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.0654 - accuracy: 0.9839 - val_loss: 2.0426 - val_accuracy: 0.6426\n",
      "Epoch 356/500\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.1006 - accuracy: 0.9768 - val_loss: 2.1078 - val_accuracy: 0.6546\n",
      "Epoch 357/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0533 - accuracy: 0.9849 - val_loss: 2.1340 - val_accuracy: 0.6265\n",
      "Epoch 358/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0977 - accuracy: 0.9789 - val_loss: 2.1791 - val_accuracy: 0.6305\n",
      "Epoch 359/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0544 - accuracy: 0.9869 - val_loss: 2.2813 - val_accuracy: 0.6145\n",
      "Epoch 360/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 2.4183 - val_accuracy: 0.5984\n",
      "Epoch 361/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0986 - accuracy: 0.9778 - val_loss: 2.1040 - val_accuracy: 0.6546\n",
      "Epoch 362/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1053 - accuracy: 0.9748 - val_loss: 2.1308 - val_accuracy: 0.6185\n",
      "Epoch 363/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0823 - accuracy: 0.9789 - val_loss: 2.3484 - val_accuracy: 0.6265\n",
      "Epoch 364/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0586 - accuracy: 0.9819 - val_loss: 2.2910 - val_accuracy: 0.6265\n",
      "Epoch 365/500\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 0.0693 - accuracy: 0.9819 - val_loss: 2.3668 - val_accuracy: 0.6024\n",
      "Epoch 366/500\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.1104 - accuracy: 0.9758 - val_loss: 2.3050 - val_accuracy: 0.6265\n",
      "Epoch 367/500\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 0.0716 - accuracy: 0.9819 - val_loss: 2.2200 - val_accuracy: 0.6265\n",
      "Epoch 368/500\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.0636 - accuracy: 0.9819 - val_loss: 2.3949 - val_accuracy: 0.6024\n",
      "Epoch 369/500\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.0582 - accuracy: 0.9778 - val_loss: 2.3831 - val_accuracy: 0.6506\n",
      "Epoch 370/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0812 - accuracy: 0.9819 - val_loss: 2.4571 - val_accuracy: 0.6064\n",
      "Epoch 371/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0710 - accuracy: 0.9839 - val_loss: 2.4097 - val_accuracy: 0.6225\n",
      "Epoch 372/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1040 - accuracy: 0.9708 - val_loss: 2.1748 - val_accuracy: 0.6104\n",
      "Epoch 373/500\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0850 - accuracy: 0.9768 - val_loss: 2.3006 - val_accuracy: 0.6145\n",
      "Epoch 374/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 2.3423 - val_accuracy: 0.5823\n",
      "Epoch 375/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0636 - accuracy: 0.9809 - val_loss: 2.1900 - val_accuracy: 0.6386\n",
      "Epoch 376/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0465 - accuracy: 0.9899 - val_loss: 2.1817 - val_accuracy: 0.6466\n",
      "Epoch 377/500\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0495 - accuracy: 0.9849 - val_loss: 2.1662 - val_accuracy: 0.6345\n",
      "Epoch 378/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0609 - accuracy: 0.9829 - val_loss: 2.1323 - val_accuracy: 0.6265\n",
      "Epoch 379/500\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0618 - accuracy: 0.9809 - val_loss: 2.1412 - val_accuracy: 0.6305\n",
      "Epoch 380/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1012 - accuracy: 0.9829 - val_loss: 2.3405 - val_accuracy: 0.6064\n",
      "Epoch 381/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0627 - accuracy: 0.9849 - val_loss: 2.1552 - val_accuracy: 0.6627\n",
      "Epoch 382/500\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 2.1657 - val_accuracy: 0.6305\n",
      "Epoch 383/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0724 - accuracy: 0.9789 - val_loss: 2.1892 - val_accuracy: 0.6386\n",
      "Epoch 384/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0879 - accuracy: 0.9748 - val_loss: 2.2188 - val_accuracy: 0.6345\n",
      "Epoch 385/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0605 - accuracy: 0.9859 - val_loss: 2.2400 - val_accuracy: 0.6386\n",
      "Epoch 386/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0804 - accuracy: 0.9789 - val_loss: 2.2579 - val_accuracy: 0.6426\n",
      "Epoch 387/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0610 - accuracy: 0.9829 - val_loss: 2.3803 - val_accuracy: 0.5984\n",
      "Epoch 388/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0743 - accuracy: 0.9799 - val_loss: 2.3238 - val_accuracy: 0.5984\n",
      "Epoch 389/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0636 - accuracy: 0.9809 - val_loss: 2.2034 - val_accuracy: 0.6185\n",
      "Epoch 390/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0345 - accuracy: 0.9869 - val_loss: 2.2708 - val_accuracy: 0.6185\n",
      "Epoch 391/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0626 - accuracy: 0.9829 - val_loss: 2.5306 - val_accuracy: 0.6104\n",
      "Epoch 392/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0969 - accuracy: 0.9758 - val_loss: 2.2195 - val_accuracy: 0.6064\n",
      "Epoch 393/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0970 - accuracy: 0.9748 - val_loss: 2.3780 - val_accuracy: 0.6024\n",
      "Epoch 394/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0981 - accuracy: 0.9768 - val_loss: 2.2381 - val_accuracy: 0.6185\n",
      "Epoch 395/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0758 - accuracy: 0.9829 - val_loss: 2.1885 - val_accuracy: 0.6064\n",
      "Epoch 396/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0934 - accuracy: 0.9789 - val_loss: 2.1341 - val_accuracy: 0.6225\n",
      "Epoch 397/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0555 - accuracy: 0.9809 - val_loss: 2.1058 - val_accuracy: 0.6586\n",
      "Epoch 398/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0833 - accuracy: 0.9809 - val_loss: 2.2147 - val_accuracy: 0.6145\n",
      "Epoch 399/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0717 - accuracy: 0.9799 - val_loss: 2.1921 - val_accuracy: 0.6265\n",
      "Epoch 400/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0553 - accuracy: 0.9859 - val_loss: 2.1778 - val_accuracy: 0.6345\n",
      "Epoch 401/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0433 - accuracy: 0.9859 - val_loss: 2.3958 - val_accuracy: 0.6185\n",
      "Epoch 402/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 2.2948 - val_accuracy: 0.6024\n",
      "Epoch 403/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0895 - accuracy: 0.9758 - val_loss: 2.4032 - val_accuracy: 0.6265\n",
      "Epoch 404/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 2.4145 - val_accuracy: 0.6024\n",
      "Epoch 405/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 2.2266 - val_accuracy: 0.6345\n",
      "Epoch 406/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0576 - accuracy: 0.9809 - val_loss: 2.1360 - val_accuracy: 0.6426\n",
      "Epoch 407/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0974 - accuracy: 0.9768 - val_loss: 2.1432 - val_accuracy: 0.6265\n",
      "Epoch 408/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0842 - accuracy: 0.9789 - val_loss: 2.1361 - val_accuracy: 0.6265\n",
      "Epoch 409/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0644 - accuracy: 0.9829 - val_loss: 2.3087 - val_accuracy: 0.6185\n",
      "Epoch 410/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0676 - accuracy: 0.9859 - val_loss: 2.1848 - val_accuracy: 0.6386\n",
      "Epoch 411/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0860 - accuracy: 0.9789 - val_loss: 2.1520 - val_accuracy: 0.6506\n",
      "Epoch 412/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0843 - accuracy: 0.9748 - val_loss: 2.0585 - val_accuracy: 0.6546\n",
      "Epoch 413/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 2.2789 - val_accuracy: 0.5944\n",
      "Epoch 414/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0522 - accuracy: 0.9799 - val_loss: 2.2219 - val_accuracy: 0.6104\n",
      "Epoch 415/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0841 - accuracy: 0.9789 - val_loss: 2.0757 - val_accuracy: 0.6586\n",
      "Epoch 416/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0910 - accuracy: 0.9738 - val_loss: 2.2491 - val_accuracy: 0.6305\n",
      "Epoch 417/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0867 - accuracy: 0.9728 - val_loss: 2.3832 - val_accuracy: 0.6024\n",
      "Epoch 418/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0837 - accuracy: 0.9809 - val_loss: 2.2631 - val_accuracy: 0.6104\n",
      "Epoch 419/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0825 - accuracy: 0.9789 - val_loss: 2.2117 - val_accuracy: 0.6265\n",
      "Epoch 420/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0693 - accuracy: 0.9819 - val_loss: 2.1864 - val_accuracy: 0.6305\n",
      "Epoch 421/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 2.1046 - val_accuracy: 0.6305\n",
      "Epoch 422/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0647 - accuracy: 0.9799 - val_loss: 2.1241 - val_accuracy: 0.6466\n",
      "Epoch 423/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 2.2462 - val_accuracy: 0.6145\n",
      "Epoch 424/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0791 - accuracy: 0.9819 - val_loss: 2.0710 - val_accuracy: 0.6506\n",
      "Epoch 425/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0896 - accuracy: 0.9799 - val_loss: 2.2142 - val_accuracy: 0.6265\n",
      "Epoch 426/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0958 - accuracy: 0.9789 - val_loss: 2.1966 - val_accuracy: 0.6225\n",
      "Epoch 427/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 2.0879 - val_accuracy: 0.6345\n",
      "Epoch 428/500\n",
      "63/63 [==============================] - 2s 40ms/step - loss: 0.0856 - accuracy: 0.9778 - val_loss: 2.3236 - val_accuracy: 0.6185\n",
      "Epoch 429/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0602 - accuracy: 0.9849 - val_loss: 2.0659 - val_accuracy: 0.6225\n",
      "Epoch 430/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0663 - accuracy: 0.9809 - val_loss: 2.1246 - val_accuracy: 0.6345\n",
      "Epoch 431/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0787 - accuracy: 0.9748 - val_loss: 2.2205 - val_accuracy: 0.6104\n",
      "Epoch 432/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0688 - accuracy: 0.9799 - val_loss: 2.1491 - val_accuracy: 0.6265\n",
      "Epoch 433/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0747 - accuracy: 0.9768 - val_loss: 2.0583 - val_accuracy: 0.6386\n",
      "Epoch 434/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0819 - accuracy: 0.9738 - val_loss: 2.3290 - val_accuracy: 0.5984\n",
      "Epoch 435/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0567 - accuracy: 0.9859 - val_loss: 2.1862 - val_accuracy: 0.6225\n",
      "Epoch 436/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0646 - accuracy: 0.9809 - val_loss: 2.2133 - val_accuracy: 0.6305\n",
      "Epoch 437/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0928 - accuracy: 0.9698 - val_loss: 2.2942 - val_accuracy: 0.6225\n",
      "Epoch 438/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0876 - accuracy: 0.9758 - val_loss: 2.0805 - val_accuracy: 0.6345\n",
      "Epoch 439/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0842 - accuracy: 0.9758 - val_loss: 2.0652 - val_accuracy: 0.6185\n",
      "Epoch 440/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0719 - accuracy: 0.9839 - val_loss: 2.1041 - val_accuracy: 0.6225\n",
      "Epoch 441/500\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0798 - accuracy: 0.9819 - val_loss: 2.1464 - val_accuracy: 0.6104\n",
      "Epoch 442/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0530 - accuracy: 0.9899 - val_loss: 2.3024 - val_accuracy: 0.6185\n",
      "Epoch 443/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0808 - accuracy: 0.9758 - val_loss: 2.2714 - val_accuracy: 0.6386\n",
      "Epoch 444/500\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0674 - accuracy: 0.9839 - val_loss: 2.1946 - val_accuracy: 0.6426\n",
      "Epoch 445/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0855 - accuracy: 0.9819 - val_loss: 2.2326 - val_accuracy: 0.6104\n",
      "Epoch 446/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0747 - accuracy: 0.9799 - val_loss: 2.1302 - val_accuracy: 0.6225\n",
      "Epoch 447/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0890 - accuracy: 0.9758 - val_loss: 2.1373 - val_accuracy: 0.6466\n",
      "Epoch 448/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0795 - accuracy: 0.9758 - val_loss: 2.1059 - val_accuracy: 0.6426\n",
      "Epoch 449/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0582 - accuracy: 0.9859 - val_loss: 2.1370 - val_accuracy: 0.6265\n",
      "Epoch 450/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0642 - accuracy: 0.9789 - val_loss: 2.1149 - val_accuracy: 0.6145\n",
      "Epoch 451/500\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 2.1895 - val_accuracy: 0.6305\n",
      "Epoch 452/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0872 - accuracy: 0.9799 - val_loss: 2.3737 - val_accuracy: 0.5984\n",
      "Epoch 453/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0840 - accuracy: 0.9758 - val_loss: 2.3207 - val_accuracy: 0.6104\n",
      "Epoch 454/500\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0957 - accuracy: 0.9738 - val_loss: 2.2096 - val_accuracy: 0.6305\n",
      "Epoch 455/500\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0867 - accuracy: 0.9778 - val_loss: 2.2625 - val_accuracy: 0.6145\n",
      "Epoch 456/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0340 - accuracy: 0.9930 - val_loss: 2.3303 - val_accuracy: 0.6145\n",
      "Epoch 457/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0691 - accuracy: 0.9799 - val_loss: 2.2932 - val_accuracy: 0.6104\n",
      "Epoch 458/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0832 - accuracy: 0.9829 - val_loss: 2.3842 - val_accuracy: 0.6104\n",
      "Epoch 459/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0865 - accuracy: 0.9758 - val_loss: 2.3748 - val_accuracy: 0.6024\n",
      "Epoch 460/500\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.0848 - accuracy: 0.9809 - val_loss: 2.2415 - val_accuracy: 0.6064\n",
      "Epoch 461/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0527 - accuracy: 0.9849 - val_loss: 2.2042 - val_accuracy: 0.6506\n",
      "Epoch 462/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0446 - accuracy: 0.9909 - val_loss: 2.2563 - val_accuracy: 0.6426\n",
      "Epoch 463/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 2.4420 - val_accuracy: 0.6064\n",
      "Epoch 464/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0768 - accuracy: 0.9748 - val_loss: 2.2153 - val_accuracy: 0.6506\n",
      "Epoch 465/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0710 - accuracy: 0.9839 - val_loss: 2.3311 - val_accuracy: 0.6225\n",
      "Epoch 466/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0826 - accuracy: 0.9789 - val_loss: 2.1736 - val_accuracy: 0.6546\n",
      "Epoch 467/500\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.0764 - accuracy: 0.9789 - val_loss: 2.2703 - val_accuracy: 0.6145\n",
      "Epoch 468/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0862 - accuracy: 0.9829 - val_loss: 2.0403 - val_accuracy: 0.6225\n",
      "Epoch 469/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0579 - accuracy: 0.9869 - val_loss: 2.2323 - val_accuracy: 0.6064\n",
      "Epoch 470/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0743 - accuracy: 0.9809 - val_loss: 2.1180 - val_accuracy: 0.6586\n",
      "Epoch 471/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0643 - accuracy: 0.9849 - val_loss: 2.0866 - val_accuracy: 0.6506\n",
      "Epoch 472/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 2.0580 - val_accuracy: 0.6426\n",
      "Epoch 473/500\n",
      "63/63 [==============================] - 4s 66ms/step - loss: 0.0630 - accuracy: 0.9829 - val_loss: 2.0733 - val_accuracy: 0.6426\n",
      "Epoch 474/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 2.1166 - val_accuracy: 0.6305\n",
      "Epoch 475/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0451 - accuracy: 0.9869 - val_loss: 2.0666 - val_accuracy: 0.6345\n",
      "Epoch 476/500\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.0443 - accuracy: 0.9809 - val_loss: 2.0886 - val_accuracy: 0.6787\n",
      "Epoch 477/500\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 2.1036 - val_accuracy: 0.6506\n",
      "Epoch 478/500\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 2.2975 - val_accuracy: 0.6426\n",
      "Epoch 479/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0784 - accuracy: 0.9789 - val_loss: 2.2167 - val_accuracy: 0.6305\n",
      "Epoch 480/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0761 - accuracy: 0.9789 - val_loss: 2.2890 - val_accuracy: 0.6265\n",
      "Epoch 481/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0502 - accuracy: 0.9869 - val_loss: 2.2421 - val_accuracy: 0.6345\n",
      "Epoch 482/500\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.0604 - accuracy: 0.9819 - val_loss: 2.3528 - val_accuracy: 0.6064\n",
      "Epoch 483/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0855 - accuracy: 0.9778 - val_loss: 2.4631 - val_accuracy: 0.6104\n",
      "Epoch 484/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0792 - accuracy: 0.9748 - val_loss: 2.4812 - val_accuracy: 0.6265\n",
      "Epoch 485/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0865 - accuracy: 0.9758 - val_loss: 2.4884 - val_accuracy: 0.6506\n",
      "Epoch 486/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0772 - accuracy: 0.9799 - val_loss: 2.2564 - val_accuracy: 0.6345\n",
      "Epoch 487/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0830 - accuracy: 0.9728 - val_loss: 2.1783 - val_accuracy: 0.6546\n",
      "Epoch 488/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0691 - accuracy: 0.9839 - val_loss: 2.2550 - val_accuracy: 0.6305\n",
      "Epoch 489/500\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.0911 - accuracy: 0.9728 - val_loss: 2.2693 - val_accuracy: 0.6345\n",
      "Epoch 490/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0533 - accuracy: 0.9859 - val_loss: 2.2928 - val_accuracy: 0.6506\n",
      "Epoch 491/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0551 - accuracy: 0.9819 - val_loss: 2.3198 - val_accuracy: 0.6225\n",
      "Epoch 492/500\n",
      "63/63 [==============================] - 4s 64ms/step - loss: 0.0968 - accuracy: 0.9768 - val_loss: 2.2020 - val_accuracy: 0.6265\n",
      "Epoch 493/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0567 - accuracy: 0.9839 - val_loss: 2.1836 - val_accuracy: 0.6546\n",
      "Epoch 494/500\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.0719 - accuracy: 0.9819 - val_loss: 2.0867 - val_accuracy: 0.6345\n",
      "Epoch 495/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.1053 - accuracy: 0.9698 - val_loss: 2.1135 - val_accuracy: 0.6426\n",
      "Epoch 496/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0842 - accuracy: 0.9758 - val_loss: 2.1444 - val_accuracy: 0.6466\n",
      "Epoch 497/500\n",
      "63/63 [==============================] - 4s 65ms/step - loss: 0.0539 - accuracy: 0.9859 - val_loss: 2.3683 - val_accuracy: 0.6185\n",
      "Epoch 498/500\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.0969 - accuracy: 0.9728 - val_loss: 2.2436 - val_accuracy: 0.6426\n",
      "Epoch 499/500\n",
      "63/63 [==============================] - 4s 61ms/step - loss: 0.0474 - accuracy: 0.9889 - val_loss: 2.0350 - val_accuracy: 0.6586\n",
      "Epoch 500/500\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.0874 - accuracy: 0.9809 - val_loss: 2.1880 - val_accuracy: 0.6627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed19732e90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.fit(X_train, y_train, validation_split=0.20, epochs=500, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 27ms/step - loss: 1.1272 - accuracy: 0.7029\n",
      "Test loss: 1.1271976232528687\n",
      "Test accuracy: 70.29%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "#X_test = np.expand_dims(X_test, axis=2)\n",
    "loss, accuracy = newmodel.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print(f'Test accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=newmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model\n",
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model('70testmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make predictions on new data\n",
    "\n",
    "data_dir='audio_speech_actors_01-24\\Actor_03'\n",
    "\n",
    "actor3_feature, actor3_emo = load_ravdess_data(data_dir)\n",
    "\n",
    "data_feature = actor3_feature\n",
    "\n",
    "# Make predictions\n",
    "data_pred = model.predict(data_feature)\n",
    "\n",
    "# Get predicted labels as emotions\n",
    "emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "predicted_emotions = [emotions[np.argmax(pred)] for pred in data_pred]\n",
    "\n",
    "\n",
    "\n",
    "file_names=[]\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "              # Load the audio file\n",
    "              file_names.append(os.path.join(data_dir, filename))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the file names and predicted emotions\n",
    "results_df = pd.DataFrame({'file_name': file_names,'actual_emotions': actor3_emo, 'predicted_emotion': predicted_emotions})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load test data and predicted labels\n",
    "test_data = pd.read_csv('results.csv') # replace with actual test data file\n",
    "\n",
    "# Extract a single column\n",
    "actual= test_data['actual_emotions'] # replace with the name of the column you want to extract\n",
    "predicted=test_data['predicted_emotion']\n",
    "\n",
    "#predicted_labels = pd.read_csv('predicted_labels.csv') # replace with actual predicted labels file\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(actual,predicted)\n",
    "\n",
    "# Create heatmap of confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', xticklabels=['Neutral', 'Calm', 'Happy', 'Sad', 'Angry', 'Fearful', 'Disgust', 'Surprised'], yticklabels=['Neutral', 'Calm', 'Happy', 'Sad', 'Angry', 'Fearful', 'Disgust', 'Surprised'], fmt='g')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Speech Emotion Recognition')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('70testmodel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = metrics.accuracy_score(actual, predicted)\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(actual, predicted)\n",
    "cohen_kappa = metrics.cohen_kappa_score(actual, predicted)\n",
    "f1_macro = metrics.f1_score(actual, predicted, average='macro')\n",
    "f1_micro = metrics.f1_score(actual, predicted, average='micro')\n",
    "f1_weighted = metrics.f1_score(actual, predicted, average='weighted')\n",
    "jaccard_macro = metrics.jaccard_score(actual, predicted, average='macro')\n",
    "jaccard_micro = metrics.jaccard_score(actual, predicted, average='micro')\n",
    "jaccard_weighted = metrics.jaccard_score(actual, predicted, average='weighted')\n",
    "hamming_loss = metrics.hamming_loss(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.734375\n",
      "Cohen Kappa Score: 0.6747448979591837\n",
      "F1 Score (Macro): 0.6879772961816306\n",
      "F1 Score (Micro): 0.7166666666666667\n",
      "F1 Score (Weighted): 0.6671757825937393\n",
      "Jaccard Score (Macro): 0.6044372294372294\n",
      "Jaccard Score (Micro): 0.5584415584415584\n",
      "Jaccard Score (Weighted): 0.5780663780663782\n",
      "Hamming Loss: 0.2833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation metrics\n",
    "\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy)\n",
    "print(\"Cohen Kappa Score:\", cohen_kappa)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "print(\"F1 Score (Micro):\", f1_micro)\n",
    "print(\"F1 Score (Weighted):\", f1_weighted)\n",
    "print(\"Jaccard Score (Macro):\", jaccard_macro)\n",
    "print(\"Jaccard Score (Micro):\", jaccard_micro)\n",
    "print(\"Jaccard Score (Weighted):\", jaccard_weighted)\n",
    "print(\"Hamming Loss:\", hamming_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
